---
layout: about
title: about
permalink: /
subtitle: <a href='https://www.inf.uni-hamburg.de/en/inst/ab/wtm/people/abawi.html'>Research Associate, University of Hamburg</a>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>Office: IKUM, F-214</p>
    <p>Vogt-KÃ¶lln Str. 30</p>
    <p>22527 Hamburg</p>

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hi there! I'm Fares Abawi, a research associate and doctoral candidate at the University of Hamburg. My work is mostly about making computers and robots smarter and more perceptive, especially in understanding what grabs our attention in different situations. I've been particularly focused on projects like "GASP: Gated Attention for Saliency Prediction" and exploring how humanoid robots can mimic human-like attention and conflict resolution through multimodal integration.

As an advocate for collaborative technology, I actively contribute to open-source software projects (check out [ImageBind-LoRA](https://github.com/fabawi/ImageBind-LoRA) and [Llama LLM distributed with Wrapyfi](https://github.com/modular-ml/wrapyfi-examples_llama)). I have also developed a framework called [Wrapyfi](https://github.com/fabawi/wrapyfi) for integrating robots and devices across multiple middleware, including ROS, ROS 2, YARP, ZeroMQ, and MQTT. To access all resources relating to Wrapyfi, visit [https://modular.ml](https://modular.ml) or the [modular ML](https://github.com/modular-ml) organization on GitHub.

Thanks for stopping by!
